\section{Introduction}

With traditional CPUs experiencing slowdowns in improvements with clock speeds,
the computing industry is looking for an alternative hardware and software
paradigm to take us into the next era of computing performance. This has led to
the increase in the number of cores on a single CPU die, with most commercial
devices containing four cores allowing four individual threads of control to run
simultaneously on a single chip. In addition to this, the growth of
computational power available in GPUs has led to the idea of using the GPUs for
general purpose computing tasks (GPGPUs). This is known as Heterogeneous
Computing and refers to any system that use more than one kind of processor. In
addition to this, there are growing numbers of devices with a Heterogeneous
System Architecture (HSA) where multiple processor types (such as CPUs and GPUs)
exist on the same die.

\section{Problem Description}

The primary task of the project was to take document filtering code running on a
CPU and investigate the use of OpenCL to allow the code to be executed on
multiple architectures, for instance a GPU, to improve overall performance of
the system.

Document filtering can place documents into two categories, with the canonical
example being spam or not spam. Documents are given to the scorer as a
collection of terms. For each term in a document, it is looked up in a profile
of spam terms. Terms in a document that are typically detected in a spam
document will have a score assigned to them in the profile, it is this score
which is collected and added to the document's overall score. At the end of
scoring, if the document has a high enough score, it is classed as spam,
otherwise it is not spam.

\section{Motivation}

Document filtering is problem of growing importance. The advent of the Internet
has resulted in a massive surge in the transfer and storage of data and
information. A prime example is email where hundreds of billions are sent every
day. Emails, and other kinds of documents, require to be filtered. This problem
is highly data parallel in nature as the classification of one document does not
affect the classification of another. With GPU manufacturers concentrating on
parallelism in their chip designs for pixel colour value generation, these
devices are thought of as being a suitable device for other highly parallel
tasks.

In addition to the large amounts of data which needs to be filtered, there is a
growing need for large enterprise data centres to be more cost effective, and to
use less energy. A heterogeneous system can not only improve performance in raw
terms, but also improve performance when measured against power and cost of
equipment. These metrics are typically quoted as performance per watt, and
performance per dollar.

\section{Related Research}

Document classification is an active area of research, with a number of papers
dedicated to the creation, analysis, and tuning of filtering algorithms. A large
number concentrate on Na{\"{\i}}ve Bayes classification
\cite{androutsopoulos2000evaluation} \cite{androutsopoulos2000learning}  with
different statistical models (for instance multi-variate Bernoulli model or a
multinomial model \cite{Schneider:2003:CEM:1067807.1067848}
\cite{mccallum1998comparison}).

There has also been work looking into the efficiency of different architectures
in the area of information filtering \cite{chen2012invited}
\cite{he2013massively} in general.

This problem more specifically relates to, and builds upon work by Wim
Vanderbauwhede et al. which has primarily focused on the use of Field-
Programmable Gate Arrays (FPGAs) to accelerate a document parser and scoring
system \cite{vanderbauwhede2013high} \cite{HybridCPUFPGA}
\cite{chalamalasetti2012evaluating} with significant success.

\section{Report Structure}

The following sections of the report will detail and discuss the problem of
efficient heterogeneous implementations for document filtering using OpenCL and
will compare results between devices, and to a traditional CPU implementation of
the same algorithm.

Chapter 2 will contain details on the background of OpenCL, the architecture
differences between devices used, and further details of document filtering
using a Na{\"{\i}}ve Bayes classifier.

Chapter 3 will discuss significant design decisions and implementation details
of the document filtering software.

Chapter 4 will evaluate the performance of the document filtering software over
a range of different devices, with a comparison to a traditional CPU
implementation, and discussion on extra metrics such as performance per watt and
performance per dollar.

Chapter 5 will summarise and discuss the results from the evaluation, and will
indicate further work opportunities to increase performance and efficiency
further.
