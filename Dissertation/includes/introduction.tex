\section{Introduction}

With traditional CPUs experiencing slowdowns in improvements to raw performance,
the computing industry is looking for an alternative hardware and software
paradigm to take us into the next era of computing performance. This has led to
the increase in the number of cores on a single CPU die, with most consumer
devices containing four cores. This allows four individual threads of control to
run simultaneously on a single chip. In addition to this, the growth of
computational power available in GPUs has led to the idea of using the GPUs for
general purpose computing tasks (GPGPUs). This is known as Heterogeneous
Computing and refers to any system that uses more than one kind of processor. In
addition to this, there are growing numbers of devices with a Heterogeneous
System Architecture (HSA) where multiple processor types (such as CPUs and GPUs)
exist on the same die.

\section{Problem Description}

The primary task of the project was to take existing document filtering code
running on a CPU and investigate the use of OpenCL to allow the code to be
executed on multiple architectures, for instance a GPU, to improve overall
performance of the system.

Document filtering can place documents into two categories, with the canonical
example being spam or not spam. Plain text documents are given to a parser which
generates a collection of terms for each document. This collection is given to a
scorer which works out  each document's score. For each term in a document, it
is looked up in a profile of spam terms. Terms in a document that are typically
detected in a spam document will have a score assigned to them in the profile,
it is this score which is collected and added to the document's overall score.
At the end of scoring, if the document has a high enough score, it is classed as
spam, otherwise it is not spam. This works for any two classification
possibilities. For example, using the Text Retrieval Conference (TREC) data
collection, the ``not spam'' class could be Entertainment articles, and the
``spam'' case could be Financial articles.

\section{Motivation}

Document filtering is problem of growing importance. The advent of the Internet
has resulted in a massive surge in the transfer and storage of data and
information. A prime example is email where hundreds of billions of emails are
sent every day. Emails, and other kinds of documents, sometimes need to be
filtered. This problem is highly data parallel in nature as the classification
of one document does not affect the classification of another. With GPU
manufacturers concentrating on parallelism in their chip designs for pixel
colour value genferation, these devices are thought of as being a suitable device
for other highly parallel tasks.

In addition to the large amounts of data which needs to be filtered, there is a
growing need for large enterprise data centres to be more cost effective, and to
use less energy. A heterogeneous system can not only improve performance in raw
terms, but also improve performance when measured against power and cost of
equipment. These metrics are typically quoted as performance per watt, and
performance per dollar.

\section{Related Research}
\label{sec:relatedResearch}

Document classification is an active area of research, with a number of papers
regularly dedicated to the creation, analysis, and tuning of filtering
algorithms. A large number concentrate on Na{\"{\i}}ve Bayes classification
\cite{androutsopoulos2000evaluation} \cite{androutsopoulos2000learning}  with
different statistical models (for instance multi-variate Bernoulli model or a
multinomial model \cite{Schneider:2003:CEM:1067807.1067848}
\cite{mccallum1998comparison}).

There has also been work looking into the efficiency of different architectures
in the area of information filtering \cite{chen2012invited}
\cite{he2013massively} in general.

This report more specifically relates to, and builds upon, work by Wim
Vanderbauwhede et al. which has primarily focused on the use of Field-
Programmable Gate Arrays (FPGAs) to accelerate a document parser and scoring
system \cite{vanderbauwhede2013high} \cite{HybridCPUFPGA}
\cite{chalamalasetti2012evaluating} with significant success.

\section{Report Structure}

The following sections of the report will detail and discuss the problem of
efficient heterogeneous implementations for document filtering using OpenCL and
will compare results between devices, and to a traditional CPU implementation of
the same algorithm.

Chapter 2 will contain details on the background of OpenCL, the architecture
differences between devices used, and further details of document filtering
using a Na{\"{\i}}ve Bayes classifier.

Chapter 3 will discuss significant implementation details and optimisations of
the document filtering software.

Chapter 4 will evaluate the performance of the document filtering software over
a range of different devices, with a comparison to a traditional CPU
implementation. The chapter will end with an in-depth discussion of the results.

Chapter 5 will summarise and discuss the results from the evaluation, and will
indicate further work opportunities to increase performance and efficiency
further.
